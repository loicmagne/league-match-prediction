{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tab-transformer-pytorch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-05T21:39:51.015038Z","iopub.execute_input":"2022-01-05T21:39:51.015386Z","iopub.status.idle":"2022-01-05T21:40:01.748632Z","shell.execute_reply.started":"2022-01-05T21:39:51.015288Z","shell.execute_reply":"2022-01-05T21:40:01.747886Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport wandb\nimport shap\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.decomposition import PCA\nfrom xgboost import XGBClassifier\nfrom tab_transformer_pytorch import TabTransformer\n\nshap.initjs()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T21:40:01.750186Z","iopub.execute_input":"2022-01-05T21:40:01.750992Z","iopub.status.idle":"2022-01-05T21:40:06.298419Z","shell.execute_reply.started":"2022-01-05T21:40:01.750960Z","shell.execute_reply":"2022-01-05T21:40:06.297744Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/league/dataset.csv')\nX = df.drop(columns=['gameId','winner'])\nY = df[['winner']]\ndel df\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\nmodel = XGBClassifier(\n    n_estimators=150,\n    learning_rate=0.14,\n    use_label_encoder=False\n)\nmodel.fit(\n    X_train, \n    Y_train.values.ravel(),\n    eval_set = [(X_train, Y_train), (X_test, Y_test)],\n    eval_metric=['error'],\n    verbose=True,\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-05T21:43:04.316958Z","iopub.execute_input":"2022-01-05T21:43:04.317283Z","iopub.status.idle":"2022-01-05T21:44:11.025572Z","shell.execute_reply.started":"2022-01-05T21:43:04.317247Z","shell.execute_reply":"2022-01-05T21:44:11.024967Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"Y_pred_test = model.predict(X_test)\nY_pred_train = model.predict(X_train)\naccuracy_test = accuracy_score(Y_test, Y_pred_test)\naccuracy_train = accuracy_score(Y_train, Y_pred_train)\nprint(f\"Test accuracy: {accuracy_test * 100.0:.2f}%\")\nprint(f\"Train accuracy: {accuracy_train * 100.0:.2f}%\")\n\nexplainer = shap.Explainer(model)\nshap_values = explainer(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T21:44:11.026899Z","iopub.execute_input":"2022-01-05T21:44:11.027575Z","iopub.status.idle":"2022-01-05T21:44:37.731523Z","shell.execute_reply.started":"2022-01-05T21:44:11.027538Z","shell.execute_reply":"2022-01-05T21:44:37.730839Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(shap_values[0][1])","metadata":{"execution":{"iopub.status.busy":"2022-01-05T21:44:37.733212Z","iopub.execute_input":"2022-01-05T21:44:37.733842Z","iopub.status.idle":"2022-01-05T21:44:37.742371Z","shell.execute_reply.started":"2022-01-05T21:44:37.733781Z","shell.execute_reply":"2022-01-05T21:44:37.741721Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"k = 0\n# visualize the first prediction's explanation\nshap.plots.waterfall(shap_values[k])\n# visualize the first prediction's explanation with a force plot\nshap.plots.force(shap_values[k])","metadata":{"execution":{"iopub.status.busy":"2022-01-05T21:49:58.354587Z","iopub.execute_input":"2022-01-05T21:49:58.355352Z","iopub.status.idle":"2022-01-05T21:49:59.423380Z","shell.execute_reply.started":"2022-01-05T21:49:58.355309Z","shell.execute_reply":"2022-01-05T21:49:59.422435Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"shap.plots.scatter(shap_values[:,\"team_1_lp_mean\"], color=shap_values)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T21:44:38.536309Z","iopub.execute_input":"2022-01-05T21:44:38.537018Z","iopub.status.idle":"2022-01-05T21:44:42.010089Z","shell.execute_reply.started":"2022-01-05T21:44:38.536964Z","shell.execute_reply":"2022-01-05T21:44:42.008981Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"shap.plots.force(shap_values[3000:3500])","metadata":{"execution":{"iopub.status.busy":"2022-01-05T21:48:08.394226Z","iopub.execute_input":"2022-01-05T21:48:08.394527Z","iopub.status.idle":"2022-01-05T21:48:09.178097Z","shell.execute_reply.started":"2022-01-05T21:48:08.394494Z","shell.execute_reply":"2022-01-05T21:48:09.177268Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network","metadata":{}},{"cell_type":"code","source":"class BasicBlock(torch.nn.Module):\n    def __init__(self,input_features, output_features):\n        super(BasicBlock, self).__init__()\n        self.nn = torch.nn.Sequential(\n            torch.nn.Linear(input_features,output_features),\n            torch.nn.BatchNorm1d(output_features),\n            torch.nn.ReLU(),\n            torch.nn.Dropout()\n        )\n    def forward(self,x):\n        return self.nn(x)\n    \n\nclass SimpleFeedForward(torch.nn.Module):\n    def __init__(self,input_features=66):\n        super(SimpleFeedForward, self).__init__()\n        self.nn = torch.nn.Sequential(\n            BasicBlock(input_features,64),\n            BasicBlock(64,32),\n            torch.nn.Linear(32,1)\n        )\n    def forward(self,x):\n        return self.nn(x)\n\nclass TorchDataset(torch.utils.data.Dataset):\n    def __init__(self,file='../input/league/dataset.csv'):\n        # Get input\n        df = pd.read_csv(file)\n        self.X = df.drop(columns=['gameId','winner']).values\n        self.Y = df[['winner']].values.astype(np.double)\n        \n        # Scale inputs + remove nan's\n        scaler = StandardScaler()\n        imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n        self.X = scaler.fit_transform(self.X)\n        self.X = imputer.fit_transform(self.X)\n        self.Y = imputer.fit_transform(self.Y)\n    \n    def __len__(self):\n        return self.X.shape[0]\n    \n    def __getitem__(self,idx):\n        return {\n            'input': self.X[idx],\n            'output': self.Y[idx]\n        }\n\n# Parameters\nbatch_size = 8\nlearning_rate = 5e-4\nepoch = 100\ncriterion = torch.nn.BCEWithLogitsLoss()\nlog = True\n\n\n# Dataset\ndataset = TorchDataset()\nn = len(dataset)\nn_test = int(0.2*n)\nn_train = n - n_test\ntrain_dataset, test_dataset = torch.utils.data.random_split(\n    dataset, \n    [n_train,n_test]\n)\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)\n\n# Model\nmodel = SimpleFeedForward()\nmodel.double()\n\n# Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\ndef metrics(pred,target):\n    accuracy = accuracy_score(target, pred)\n    precision = precision_score(target, pred)\n    recall = recall_score(target, pred)\n    f1 = f1_score(target, pred)\n    return accuracy, precision, recall, f1\n\ndef visualize_embedding(model,dataset):\n    # Visualize embedding\n    pca = PCA(3)\n\n    emb = model.embedding.weight.cpu().detach().numpy()\n    emb_2d = pca.fit_transform(emb)\n\n    plt.scatter(emb_2d[:,0],emb_2d[:,1])\n    for i, pt in enumerate(emb_2d):\n        plt.text(pt[0]+0.03,pt[1]-0.03, table[dataset.le.classes_[i]], fontsize=11)\n    plt.show()\n\n# Wandb\nif log:\n    wandb.init(project=\"league\")\n    wandb.watch(model)\n\nfor k in tqdm(range(epoch)):\n    train_loss, test_loss, train_acc, test_acc = 0,0,0,0\n    # Train\n    model.train()\n    for batch in train_loader:\n        X = batch['input']\n        Y = batch['output']\n        pred = model(X)\n        loss = criterion(pred,Y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Add metrics\n        train_acc += torch.sum((torch.sigmoid(pred)>0.5).detach() == Y).item()\n        train_loss += loss.item()\n    # Test  \n    model.eval()\n    with torch.no_grad():\n        for batch in test_loader:\n            X = batch['input']\n            Y = batch['output']\n            pred = model(X)\n            loss = criterion(pred,Y)\n            \n            # Add metrics\n            test_acc += torch.sum((torch.sigmoid(pred)>0.5).detach() == Y).item()\n            test_loss += loss.item()\n    \n    # Log\n    train_loss /= len(train_dataset)\n    train_acc /= n_train\n    test_loss /= len(test_dataset)\n    test_acc /= n_test\n    if log:\n        wandb.log({\n            \"loss_train\" : train_loss,\n            \"loss_test\" : test_loss,\n            \"acc_train\" : train_acc,\n            \"acc_test\" : test_acc,\n        })","metadata":{"execution":{"iopub.status.busy":"2022-01-04T23:32:48.084249Z","iopub.execute_input":"2022-01-04T23:32:48.084721Z","iopub.status.idle":"2022-01-04T23:55:23.071636Z","shell.execute_reply.started":"2022-01-04T23:32:48.084676Z","shell.execute_reply":"2022-01-04T23:55:23.070516Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# TabTransformer","metadata":{}},{"cell_type":"code","source":"class TorchDataset(torch.utils.data.Dataset):\n    def __init__(self,file='../input/league-cont-cat/dataset.csv'):\n        # Get input\n        df = pd.read_csv(file)\n        self.X = df.drop(columns=['gameId','winner']).values\n        self.Y = df[['winner']].values.astype(np.double)\n        self.cat = self.X[:,:60]\n        self.cont = self.X[:,60:]\n        \n        # Process each inputs\n        scaler = StandardScaler()\n        imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n        self.cont = scaler.fit_transform(self.cont)\n        self.cont = imputer.fit_transform(self.cont)\n        self.Y = imputer.fit_transform(self.Y)\n        \n        self.cat_sizes = []\n        for k in range(self.cat.shape[1]):\n            le = LabelEncoder()\n            self.cat[:,k] = le.fit_transform(self.cat[:,k].astype(str))\n            self.cat_sizes.append(len(le.classes_))\n        \n        self.cat = self.cat.astype(int)\n    \n    def __len__(self):\n        return self.X.shape[0]\n    \n    def __getitem__(self,idx):\n        return {\n            'cont': self.cont[idx],\n            'cat': self.cat[idx],\n            'output': self.Y[idx]\n        }\n\n# Parameters\nbatch_size = 32\nlearning_rate = 3e-4\nepoch = 100\ncriterion = torch.nn.BCEWithLogitsLoss()\nlog = True\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Dataset\ndataset = TorchDataset()\nn = len(dataset)\nn_test = int(0.2*n)\nn_train = n - n_test\ntrain_dataset, test_dataset = torch.utils.data.random_split(\n    dataset, \n    [n_train,n_test]\n)\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)\n\n# Model\nmodel = TabTransformer(\n    categories = dataset.cat_sizes,     # tuple containing the number of unique values within each category\n    num_continuous = 66,                # number of continuous values\n    dim = 16,                           # dimension, paper set at 32\n    dim_out = 1,                        # binary prediction, but could be anything\n    depth = 6,                          # depth, paper recommended 6\n    heads = 8,                          # heads, paper recommends 8\n    attn_dropout = 0.6,                 # post-attention dropout\n    ff_dropout = 0.6,                   # feed forward dropout\n    mlp_hidden_mults = (4, 2),          # relative multiples of each hidden dimension of the last mlp to logits\n    mlp_act = torch.nn.ReLU(),          # activation for final mlp, defaults to relu, but could be anything else (selu etc)\n)\nmodel.double()\nmodel.to(device)\n\n# Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n\n# Wandb\nif log:\n    wandb.init(project=\"league\")\n    wandb.watch(model)\n\nfor k in range(epoch):\n    train_loss, test_loss, train_acc, test_acc = 0,0,0,0\n    # Train\n    model.train()\n    for batch in tqdm(train_loader):\n        cat = batch['cat'].to(device)\n        cont = batch['cont'].to(device)\n        Y = batch['output'].to(device)\n        pred = model(cat,cont)\n        loss = criterion(pred,Y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Add metrics\n        train_acc += torch.sum((torch.sigmoid(pred)>0.5).detach() == Y).item()\n        train_loss += loss.item()\n    # Test  \n    model.eval()\n    with torch.no_grad():\n        for batch in test_loader:\n            cat = batch['cat'].to(device)\n            cont = batch['cont'].to(device)\n            Y = batch['output'].to(device)\n            pred = model(cat,cont)\n            loss = criterion(pred,Y)\n            \n            # Add metrics\n            test_acc += torch.sum((torch.sigmoid(pred)>0.5).detach() == Y).item()\n            test_loss += loss.item()\n    \n    # Log\n    train_loss /= len(train_dataset)\n    train_acc /= n_train\n    test_loss /= len(test_dataset)\n    test_acc /= n_test\n    if log:\n        wandb.log({\n            \"loss_train\" : train_loss,\n            \"loss_test\" : test_loss,\n            \"acc_train\" : train_acc,\n            \"acc_test\" : test_acc,\n        })\n    else:\n        print(f'Loss train: {train_loss}, Loss test: {test_loss}, Acc train: {train_acc}, Acc test: {test_acc}')","metadata":{"execution":{"iopub.status.busy":"2022-01-05T12:12:44.064068Z","iopub.execute_input":"2022-01-05T12:12:44.064421Z","iopub.status.idle":"2022-01-05T13:10:43.321350Z","shell.execute_reply.started":"2022-01-05T12:12:44.064386Z","shell.execute_reply":"2022-01-05T13:10:43.320553Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}